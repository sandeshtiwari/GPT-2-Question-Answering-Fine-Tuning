# GPT-2 Question-Answering Fine-Tuning

This project fine-tunes a GPT-2 model to generate answers for question-answering tasks using a custom instruction-based dataset. It builds on pre-trained model weights to adapt GPT-2 for generating responses to specific questions.

To run the code in this project, you'll need the following packages:

- `matplotlib`
- `tensorflow>=2.15.0`
- `tqdm>=4.66`
- `torch`
- `torchvision`
- `numpy`
- `tiktoken`

You will also need to install ollama to run the validation part of the notebook.
